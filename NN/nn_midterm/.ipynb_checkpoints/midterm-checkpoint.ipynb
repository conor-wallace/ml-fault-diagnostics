{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAT 5983 Midterm\n",
    "#### Conor Wallace, bhd445\n",
    "#### 11-01-2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.\n",
    "\n",
    "#### Problem Statement\n",
    "\n",
    "The objective of this problem was to the minimize the energy function stated below, given an arbitrary data set consisting of coordinates, $x \\in \\mathbb{R}^{2 \\times n}$. The number of given samples, $n$, is an $8x8$ grid of uniformly distributed coordinates over the range $[0, 5] \\times [0, 5]$.\n",
    "\n",
    "\\begin{equation}\n",
    "    \\min{G(x_{i}) = \\lVert\\ x_{i} - p_{1} \\rVert^{2} \\cdot \\lVert\\ x_{i} - p_{2} \\rVert^{2} \\cdot \\lVert\\ x_{i} - p_{3} \\rVert^{2}}\\\\\n",
    "    \\text{for} \\, x_{i},p_{i} \\in \\mathbb{R}^2\\\\\n",
    "    \\text{such that} \\, 0 \\preceq x_{i} \\preceq 5 \n",
    "\\end{equation}\n",
    "\n",
    "Steepest descent was used to minimize the energy function by taking the gradient of the function, multiplying it by the step size $\\alpha$, and adding it to the current position as can be seen in the equation below.\n",
    "\n",
    "\\begin{equation}\n",
    "    \\dot{x(t)} = x(t) - \\alpha \\nabla G(x(t))\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "#### Code Review\n",
    "\n",
    "The code is broken up into four segments: the objective function, the gradient of the objective function, the gradient descent algorithm, and finally the trajectory plotting. The algorithm for steepest descent is summarized below.\n",
    "\n",
    "__Require__: Starting point $x \\in dom(f)$\n",
    "\n",
    "__repeat__\n",
    "> Compute search direction $\\nabla G(x(t))$\n",
    "\n",
    "> Update: $x^{+} := x - \\alpha \\nabla G(x(t))$\n",
    "\n",
    "> until convergence criterion is satisfied\n",
    "\n",
    "#### Analysis\n",
    "\n",
    "As stated above, the algorithm begins by generating an $[8 \\times 8]$ random set of coordinate data in the range $[0, 5] \\times [0, 5]$. Next, each sample is evaluated in the objective and subsequently the gradient of the objective function in order to iteratively compute the next coordinate. In Fig. (1), the plot shows $64$ scattered initial coordinates and their trajectories along the course of the algorithm. It can be seen that each sample gravitated towards the nearest initial memory which perfectly embodies the power of steepest descent in finding global minimums during training.\n",
    "\n",
    "| <img src=\"figures/traj.png\"> |\n",
    "| :--: |\n",
    "| <center>*Fig. (1) Steepest Descent Convergence*</center> |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import pandas\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "900.0000000000005"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Energy Function\n",
    "\n",
    "parameters: input data vector, x_i, matrix of memory vectors, p\n",
    "\n",
    "output: euclidean norm between input vector and memory p_i squared \n",
    "        multiplied by each subsequent memory norm \n",
    "'''\n",
    "def G(pin, p):\n",
    "    #G(x) = l2(x - p1)^2*l2(x - p2)^2*l2(x - p3)^2\n",
    "    f = 1\n",
    "    for p_t in p:\n",
    "        f *= (np.linalg.norm((pin - p_t), ord=2)**2)\n",
    "    return f\n",
    "\n",
    "p = []\n",
    "p1 = np.array(([2],[1]))\n",
    "p.append(p1)\n",
    "p2 = np.array(([3],[3]))\n",
    "p.append(p2)\n",
    "p3 = np.array(([1],[3]))\n",
    "p.append(p3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Graident of the energy function\n",
    "\n",
    "parameters, \n",
    "'''\n",
    "def gradient(x, p):\n",
    "    grad = 1.0\n",
    "    for p_t in p:\n",
    "        derivative = np.array(([float(2*(x[0] - p_t[0]))],[float(2*(x[1] - p_t[1]))]))\n",
    "        f = 1.\n",
    "        for q_t in p:\n",
    "            if not np.array_equal(q_t, p_t):\n",
    "                f *= float((np.linalg.norm((x - q_t), ord=2)**2))\n",
    "        \n",
    "        grad += derivative*f\n",
    "\n",
    "    return grad        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[4.01168507]\n",
      "  [4.03787257]]\n",
      "\n",
      " [[3.09790072]\n",
      "  [4.68866149]]\n",
      "\n",
      " [[4.22863275]\n",
      "  [3.58829819]]\n",
      "\n",
      " [[3.97950296]\n",
      "  [4.56971068]]\n",
      "\n",
      " [[4.01733317]\n",
      "  [2.71286869]]\n",
      "\n",
      " [[1.5703243 ]\n",
      "  [1.79035766]]\n",
      "\n",
      " [[3.33198155]\n",
      "  [2.84891932]]\n",
      "\n",
      " [[4.06782728]\n",
      "  [0.30841496]]\n",
      "\n",
      " [[4.47144764]\n",
      "  [2.15216346]]\n",
      "\n",
      " [[0.50169956]\n",
      "  [3.21901085]]\n",
      "\n",
      " [[3.31276064]\n",
      "  [2.6544952 ]]\n",
      "\n",
      " [[2.53760922]\n",
      "  [3.36771374]]\n",
      "\n",
      " [[0.74682954]\n",
      "  [2.21691437]]\n",
      "\n",
      " [[4.80457613]\n",
      "  [1.48728421]]\n",
      "\n",
      " [[0.68161877]\n",
      "  [1.08879089]]\n",
      "\n",
      " [[3.06496203]\n",
      "  [2.35877496]]\n",
      "\n",
      " [[3.37849695]\n",
      "  [1.7941956 ]]\n",
      "\n",
      " [[2.12227523]\n",
      "  [0.37953178]]\n",
      "\n",
      " [[1.08710483]\n",
      "  [2.60992172]]\n",
      "\n",
      " [[1.96420522]\n",
      "  [3.85813216]]\n",
      "\n",
      " [[2.67023876]\n",
      "  [1.2142237 ]]\n",
      "\n",
      " [[3.69569173]\n",
      "  [4.01060328]]\n",
      "\n",
      " [[2.54913467]\n",
      "  [2.42033414]]\n",
      "\n",
      " [[2.32418616]\n",
      "  [1.60295812]]\n",
      "\n",
      " [[4.12085956]\n",
      "  [3.78821239]]\n",
      "\n",
      " [[0.03443693]\n",
      "  [3.2192642 ]]\n",
      "\n",
      " [[3.51515542]\n",
      "  [3.89718213]]\n",
      "\n",
      " [[3.21289882]\n",
      "  [4.98933752]]\n",
      "\n",
      " [[1.73994527]\n",
      "  [0.46454529]]\n",
      "\n",
      " [[3.39340271]\n",
      "  [4.09656186]]\n",
      "\n",
      " [[3.8091408 ]\n",
      "  [2.49734688]]\n",
      "\n",
      " [[4.99277877]\n",
      "  [3.67686795]]\n",
      "\n",
      " [[0.20202611]\n",
      "  [0.20331817]]\n",
      "\n",
      " [[2.81536679]\n",
      "  [4.70919499]]\n",
      "\n",
      " [[1.36407381]\n",
      "  [0.81744072]]\n",
      "\n",
      " [[2.00375125]\n",
      "  [4.6003487 ]]\n",
      "\n",
      " [[1.51248804]\n",
      "  [0.77543463]]\n",
      "\n",
      " [[4.23801402]\n",
      "  [1.44336725]]\n",
      "\n",
      " [[2.92797217]\n",
      "  [2.66762208]]\n",
      "\n",
      " [[2.0277526 ]\n",
      "  [4.19818761]]\n",
      "\n",
      " [[4.25566183]\n",
      "  [1.65609735]]\n",
      "\n",
      " [[1.59571884]\n",
      "  [1.02413253]]\n",
      "\n",
      " [[0.82475647]\n",
      "  [0.68431687]]\n",
      "\n",
      " [[0.52970752]\n",
      "  [4.41044953]]\n",
      "\n",
      " [[1.75118099]\n",
      "  [1.61205425]]\n",
      "\n",
      " [[0.20873688]\n",
      "  [3.43522651]]\n",
      "\n",
      " [[3.44383721]\n",
      "  [3.67611771]]\n",
      "\n",
      " [[2.86182862]\n",
      "  [1.9787831 ]]\n",
      "\n",
      " [[4.67703016]\n",
      "  [2.33794308]]\n",
      "\n",
      " [[2.7150557 ]\n",
      "  [4.72978848]]\n",
      "\n",
      " [[2.53762287]\n",
      "  [2.99622811]]\n",
      "\n",
      " [[0.20694223]\n",
      "  [0.94584665]]\n",
      "\n",
      " [[0.34703141]\n",
      "  [1.62661743]]\n",
      "\n",
      " [[1.77768707]\n",
      "  [0.59378298]]\n",
      "\n",
      " [[4.88805525]\n",
      "  [1.2274867 ]]\n",
      "\n",
      " [[1.73876066]\n",
      "  [4.86817093]]\n",
      "\n",
      " [[0.98004102]\n",
      "  [1.17397759]]\n",
      "\n",
      " [[4.20070235]\n",
      "  [1.13274239]]\n",
      "\n",
      " [[4.21011517]\n",
      "  [1.49294397]]\n",
      "\n",
      " [[3.61694223]\n",
      "  [0.09641683]]\n",
      "\n",
      " [[0.76522759]\n",
      "  [2.355946  ]]\n",
      "\n",
      " [[4.11311802]\n",
      "  [4.99812136]]\n",
      "\n",
      " [[1.62069373]\n",
      "  [1.38743244]]\n",
      "\n",
      " [[0.87123439]\n",
      "  [3.15476935]]]\n",
      "[[[2.97237417]\n",
      "  [2.97283513]]\n",
      "\n",
      " [[2.97237417]\n",
      "  [2.97283513]]\n",
      "\n",
      " [[2.97237417]\n",
      "  [2.97283513]]\n",
      "\n",
      " [[2.97237417]\n",
      "  [2.97283513]]\n",
      "\n",
      " [[2.97237417]\n",
      "  [2.97283513]]\n",
      "\n",
      " [[1.9805969 ]\n",
      "  [0.98117491]]\n",
      "\n",
      " [[2.97237417]\n",
      "  [2.97283513]]\n",
      "\n",
      " [[1.9805969 ]\n",
      "  [0.98117491]]\n",
      "\n",
      " [[2.97237417]\n",
      "  [2.97283513]]\n",
      "\n",
      " [[0.97617468]\n",
      "  [2.9748625 ]]\n",
      "\n",
      " [[2.97237417]\n",
      "  [2.97283513]]\n",
      "\n",
      " [[2.97237417]\n",
      "  [2.97283513]]\n",
      "\n",
      " [[0.97617468]\n",
      "  [2.9748625 ]]\n",
      "\n",
      " [[2.97237417]\n",
      "  [2.97283513]]\n",
      "\n",
      " [[1.9805969 ]\n",
      "  [0.98117491]]\n",
      "\n",
      " [[2.97237417]\n",
      "  [2.97283513]]\n",
      "\n",
      " [[2.97237417]\n",
      "  [2.97283513]]\n",
      "\n",
      " [[1.9805969 ]\n",
      "  [0.98117491]]\n",
      "\n",
      " [[0.97617468]\n",
      "  [2.9748625 ]]\n",
      "\n",
      " [[0.97617468]\n",
      "  [2.9748625 ]]\n",
      "\n",
      " [[1.9805969 ]\n",
      "  [0.98117491]]\n",
      "\n",
      " [[2.97237417]\n",
      "  [2.97283513]]\n",
      "\n",
      " [[2.97237417]\n",
      "  [2.97283513]]\n",
      "\n",
      " [[1.9805969 ]\n",
      "  [0.98117491]]\n",
      "\n",
      " [[2.97237417]\n",
      "  [2.97283513]]\n",
      "\n",
      " [[0.97617468]\n",
      "  [2.9748625 ]]\n",
      "\n",
      " [[2.97237417]\n",
      "  [2.97283513]]\n",
      "\n",
      " [[2.97237417]\n",
      "  [2.97283513]]\n",
      "\n",
      " [[1.9805969 ]\n",
      "  [0.98117491]]\n",
      "\n",
      " [[2.97237417]\n",
      "  [2.97283513]]\n",
      "\n",
      " [[2.97237417]\n",
      "  [2.97283513]]\n",
      "\n",
      " [[2.97237417]\n",
      "  [2.97283513]]\n",
      "\n",
      " [[1.9805969 ]\n",
      "  [0.98117491]]\n",
      "\n",
      " [[2.97237417]\n",
      "  [2.97283513]]\n",
      "\n",
      " [[1.9805969 ]\n",
      "  [0.98117491]]\n",
      "\n",
      " [[0.97617468]\n",
      "  [2.9748625 ]]\n",
      "\n",
      " [[1.9805969 ]\n",
      "  [0.98117491]]\n",
      "\n",
      " [[2.97237417]\n",
      "  [2.97283513]]\n",
      "\n",
      " [[2.97237417]\n",
      "  [2.97283513]]\n",
      "\n",
      " [[0.97617468]\n",
      "  [2.9748625 ]]\n",
      "\n",
      " [[2.97237417]\n",
      "  [2.97283513]]\n",
      "\n",
      " [[1.9805969 ]\n",
      "  [0.98117491]]\n",
      "\n",
      " [[1.9805969 ]\n",
      "  [0.98117491]]\n",
      "\n",
      " [[0.97617468]\n",
      "  [2.9748625 ]]\n",
      "\n",
      " [[1.9805969 ]\n",
      "  [0.98117491]]\n",
      "\n",
      " [[0.97617468]\n",
      "  [2.9748625 ]]\n",
      "\n",
      " [[2.97237417]\n",
      "  [2.97283513]]\n",
      "\n",
      " [[2.97237417]\n",
      "  [2.97283513]]\n",
      "\n",
      " [[2.97237417]\n",
      "  [2.97283513]]\n",
      "\n",
      " [[2.97237417]\n",
      "  [2.97283513]]\n",
      "\n",
      " [[2.97237417]\n",
      "  [2.97283513]]\n",
      "\n",
      " [[1.9805969 ]\n",
      "  [0.98117491]]\n",
      "\n",
      " [[0.97617468]\n",
      "  [2.9748625 ]]\n",
      "\n",
      " [[1.9805969 ]\n",
      "  [0.98117491]]\n",
      "\n",
      " [[2.97237417]\n",
      "  [2.97283513]]\n",
      "\n",
      " [[0.97617468]\n",
      "  [2.9748625 ]]\n",
      "\n",
      " [[1.9805969 ]\n",
      "  [0.98117491]]\n",
      "\n",
      " [[1.9805969 ]\n",
      "  [0.98117491]]\n",
      "\n",
      " [[2.97237417]\n",
      "  [2.97283513]]\n",
      "\n",
      " [[1.9805969 ]\n",
      "  [0.98117491]]\n",
      "\n",
      " [[0.97617468]\n",
      "  [2.9748625 ]]\n",
      "\n",
      " [[2.97237417]\n",
      "  [2.97283513]]\n",
      "\n",
      " [[1.9805969 ]\n",
      "  [0.98117491]]\n",
      "\n",
      " [[0.97617468]\n",
      "  [2.9748625 ]]]\n"
     ]
    }
   ],
   "source": [
    "num_rows = 8\n",
    "num_columns = 8\n",
    "num_features = 2\n",
    "init_grid = np.random.uniform(size=(num_rows, num_columns, num_features), low=0, high=5)\n",
    "init_grid = np.reshape(init_grid, [num_rows*num_columns,2])\n",
    "# print(grid)\n",
    "p = []\n",
    "p1 = np.array(([2],[1]))\n",
    "p.append(p1)\n",
    "p2 = np.array(([3],[3] ))\n",
    "p.append(p2)\n",
    "p3 = np.array(([1],[3]))\n",
    "p.append(p3)\n",
    "\n",
    "pin = np.array(([2.736], [0.30035]))\n",
    "\n",
    "grid = []\n",
    "start_grid = []\n",
    "for i in range(init_grid.shape[0]):\n",
    "#     print(grid[i].shape)\n",
    "    grid.append(init_grid[i].reshape(2,1))\n",
    "    start_grid.append(init_grid[i].reshape(2,1))\n",
    "    \n",
    "grid = np.array(grid)\n",
    "start_grid = np.array(start_grid)\n",
    "print(grid)\n",
    "\n",
    "alpha = 0.001\n",
    "paths = []\n",
    "for t in range(1000):\n",
    "    path = []\n",
    "    for i in range(grid.shape[0]):\n",
    "        grid[i] = grid[i] + alpha*(-1*gradient(grid[i], p))\n",
    "        path.append(grid[i])\n",
    "    paths.append(path)\n",
    "#     pin = pin + alpha*(-1*gradient(pin, p))\n",
    "# print pin\n",
    "print grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 2, 1)\n",
      "(64, 2, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print start_grid.shape\n",
    "print grid.shape\n",
    "\n",
    "start_grid = np.reshape(start_grid, [64, 2])\n",
    "grid = np.reshape(grid, [64, 2])\n",
    "\n",
    "ax1 = plt.axes()\n",
    "\n",
    "\n",
    "for i in range(grid.shape[0]):\n",
    "    x_end = grid[i, 0] - start_grid[i, 0]\n",
    "    y_end = grid[i, 1] - start_grid[i, 1]\n",
    "    ax1.arrow(start_grid[i,0], start_grid[i,1], x_end, y_end)\n",
    "\n",
    "plt.xlim(0,5)\n",
    "plt.ylim(0,5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.\n",
    "\n",
    "#### Problem Statement\n",
    "\n",
    "In this problem, a given data set $x \\in \\mathbb{R}^{m \\times n}$ is represented using the standard basis, the haar basis, and the eigein basis in order to see the effects of different bases on the sparsity of data.\n",
    "\n",
    "#### Code Review\n",
    "\n",
    "The code is split up into three blocks: statistical helper functions, original problem data, and a second random $\\mathbb{R}^{16 \\times 100}$ problem. As the original problem requested, the code below is capable of computing the bases for any dataset of any dimensionality.\n",
    "\n",
    "#### Analysis\n",
    "\n",
    "$x \\in \\mathbb{R}^{2 \\times 5}$\n",
    "\n",
    "- Standard Basis(x):\n",
    "    - mean: [0 0]\n",
    "    - cumulative variance: [2 0.8]\n",
    "    \n",
    "- Haar Basis(x):\n",
    "    - mean: [0 0]\n",
    "    - cumulative variance: [1.6 1.2]\n",
    "    \n",
    "- Eigen Basis(x):\n",
    "    - mean: [0 0]\n",
    "    - cumulative variance: [2.03245553 0.76754447]\n",
    "    \n",
    "No conclusions could be made from the mean of the given data from the problem. However, the results of the cumulative variance yields an interesting result. All bases' cumulative variance vectors sum to 2.8, however the sparsity of these vectors is different. The standard basis is exactly equal to the variance of each feature vector (row vector) in the data set. The haar basis forces the variance of each row vector to be closer to the mean of their respective variances. Finally, the eigen basis typically puts more weight onto the feature vector with the most variance which is a profound property when determining which features are responsible for the most information in a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper Functions\n",
    "def isSymmetric(matrix):\n",
    "    tr = np.transpose(matrix)\n",
    "    if tr not in matrix:\n",
    "        return False\n",
    "    \n",
    "    return True\n",
    "    \n",
    "def next_power2(n): \n",
    "    count = 0; \n",
    "    if (n and not(n & (n - 1))): \n",
    "        return n \n",
    "    while( n != 0): \n",
    "        n >>= 1\n",
    "        count += 1\n",
    "    return 1 << count; \n",
    "\n",
    "def reshape_x(x):\n",
    "    dx = 0\n",
    "    dy = 0\n",
    "    dmax = 0\n",
    "    if x.ndim > 1:\n",
    "        if x.shape[0]%2 != 0:\n",
    "            dx = next_power2(x.shape[0])-x.shape[0]\n",
    "        x = np.pad(x,(0,dx),'constant')\n",
    "    else:\n",
    "        if len(x)%2 != 0:\n",
    "            dx = next_power2(len(x))-len(x)\n",
    "        x = np.pad(x,(0,dx),'constant')\n",
    "    return x\n",
    "\n",
    "def haarMatrix(n):\n",
    "    # Allow only size n of power 2\n",
    "    n = 2**np.ceil(np.log2(n))\n",
    "    if n > 2:\n",
    "        h = haarMatrix(n / 2)\n",
    "    else:\n",
    "        return np.array([[1, 1], [1, -1]])\n",
    "    A = np.array([[1, 1], [1, -1]])\n",
    "    h_n = np.kron(h, A)\n",
    "    return h_n\n",
    "\n",
    "#Statistical Functions\n",
    "def autoCovariance(x):\n",
    "    m = np.zeros((x.shape[0], x.shape[0]))\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[0]):\n",
    "            for n in range(x.shape[1]):\n",
    "                m[i, j] += x[i, n]*x[j, n]\n",
    "            m[i, j] = (1.0/x.shape[1])*m[i, j]\n",
    "\n",
    "    return m\n",
    "\n",
    "def expectationVector(x):\n",
    "    e = np.zeros((x.shape[0]))\n",
    "    for n in range(x.shape[1]):\n",
    "        e += x[:, n]\n",
    "    \n",
    "    return e/x.shape[1]\n",
    "\n",
    "def varianceVector(x, e):\n",
    "    v = np.zeros((x.shape[0]))\n",
    "    for i in range(x.shape[0]):\n",
    "        for n in range(x.shape[1]):\n",
    "            v[i] += (x[i, n] - e[i])**2\n",
    "    \n",
    "    return v/x.shape[1]\n",
    "\n",
    "\n",
    "#Basis Functions\n",
    "def std_basis_variance(x):\n",
    "    basis = np.identity(x.shape[0])\n",
    "    var = np.dot(basis, x)\n",
    "    \n",
    "    return var\n",
    "\n",
    "def haar_basis_variance(x):\n",
    "    basis = haarMatrix(x.shape[0])\n",
    "    var = (1.0/math.sqrt(2))*np.dot(basis, x)\n",
    "    \n",
    "    return var\n",
    "\n",
    "def eig_basis_variance(x, eig):\n",
    "    var = np.dot(np.linalg.inv(eig), x)\n",
    "    \n",
    "    return var\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "symmetric\n",
      "[2.03245553 0.76754447]\n",
      "[[ 0.98708746 -0.16018224]\n",
      " [ 0.16018224  0.98708746]]\n",
      "std basis: \n",
      "[[ 2.  1.  0. -1. -2.]\n",
      " [-1.  1.  1.  0. -1.]]\n",
      "haar basis: \n",
      "[[ 0.70710678  1.41421356  0.70710678 -0.70710678 -2.12132034]\n",
      " [ 2.12132034  0.         -0.70710678 -0.70710678 -0.70710678]]\n",
      "eigen basis: \n",
      "[[ 1.81399267  1.1472697   0.16018224 -0.98708746 -2.13435716]\n",
      " [-1.30745194  0.82690521  0.98708746  0.16018224 -0.66672297]]\n",
      "std mean: \n",
      "[0. 0.]\n",
      "std var: \n",
      "[2.  0.8]\n",
      "haar mean: \n",
      "[0. 0.]\n",
      "haar var: \n",
      "[1.6 1.2]\n",
      "eig mean: \n",
      "[0. 0.]\n",
      "eig var: \n",
      "[2.03245553 0.76754447]\n"
     ]
    }
   ],
   "source": [
    "x = np.zeros((2,5))\n",
    "row1 = [2, 1, 0, -1, -2]\n",
    "row2 = [-1, 1, 1, 0, -1]\n",
    "In [4]:\n",
    "\n",
    "x[0, :] = row1\n",
    "x[1, :] = row2\n",
    "# print x\n",
    "m = autoCovariance(x)\n",
    "e = expectationVector(x)\n",
    "v = varianceVector(x, e)\n",
    "if isSymmetric(m):\n",
    "    print \"symmetric\"\n",
    "    \n",
    "else:\n",
    "    print \"not symmetric\"\n",
    "    \n",
    "eigval, eigvec = np.linalg.eig(m)\n",
    "print eigval\n",
    "print eigvec\n",
    "\n",
    "std_basis = np.zeros((x.shape[0], x.shape[1]))\n",
    "haar_basis = np.zeros((x.shape[0], x.shape[1]))\n",
    "eig_basis = np.zeros((x.shape[0], x.shape[1]))\n",
    "\n",
    "for n in range(x.shape[1]):\n",
    "    std_basis[:,n] = std_basis_variance(x[:, n])\n",
    "    haar_basis[:,n] = haar_basis_variance(x[:, n])\n",
    "    eig_basis[:,n] = eig_basis_variance(x[:, n], eigvec)\n",
    "                     \n",
    "print \"std basis: \\n\", std_basis\n",
    "print \"haar basis: \\n\", haar_basis\n",
    "print \"eigen basis: \\n\", eig_basis\n",
    "\n",
    "std_e = expectationVector(std_basis)\n",
    "std_v = varianceVector(std_basis, std_e)\n",
    "haar_e = expectationVector(haar_basis)\n",
    "haar_v = varianceVector(haar_basis, haar_e)\n",
    "eig_e = expectationVector(eig_basis)\n",
    "eig_v = varianceVector(eig_basis, eig_e)\n",
    "\n",
    "print \"std mean: \\n\", std_e\n",
    "print \"std var: \\n\", std_v\n",
    "print \"haar mean: \\n\", haar_e\n",
    "print \"haar var: \\n\", haar_v\n",
    "print \"eig mean: \\n\", eig_e\n",
    "print \"eig var: \\n\", eig_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "symmetric\n",
      "[4.05921023 0.1397512  0.12171234 0.11973429 0.10900943 0.10473619\n",
      " 0.03858271 0.04078886 0.04849027 0.05078754 0.05193167 0.06480378\n",
      " 0.07142423 0.07882095 0.08895974 0.08866477]\n",
      "[[-0.26740712 -0.16474218 -0.14399399 -0.06046917 -0.36799392  0.27713465\n",
      "  -0.47253793  0.12335741  0.32049888  0.22469     0.18318073 -0.13564087\n",
      "  -0.10582063  0.0316239  -0.39383262  0.23188233]\n",
      " [-0.21428931  0.43262305 -0.06655953  0.37563568  0.19526344 -0.10510171\n",
      "   0.02791042  0.0428186  -0.20370543 -0.01656933  0.54082391 -0.2440402\n",
      "  -0.18060921  0.22274646  0.0582742   0.30025044]\n",
      " [-0.22794095  0.10293251 -0.4304105   0.03351158 -0.0033072  -0.10266725\n",
      "   0.36758962  0.13615775  0.2775681   0.42501262 -0.11835837  0.02705229\n",
      "   0.28619936 -0.31187901  0.25465866  0.26534715]\n",
      " [-0.2545018  -0.27623237  0.03906185 -0.12539802  0.0956287  -0.50839746\n",
      "  -0.33544757 -0.37820427 -0.2124452  -0.0525123  -0.02147526 -0.1956891\n",
      "   0.41560896 -0.04272001  0.0105      0.23913526]\n",
      " [-0.26658606 -0.47036103  0.02324235  0.29828873 -0.18844725  0.30608366\n",
      "   0.42479111 -0.30324474 -0.29225307  0.08346758 -0.15397548 -0.22914741\n",
      "  -0.18308191  0.1017143   0.02049143  0.06075524]\n",
      " [-0.25157982  0.11678519  0.43250041  0.28886632 -0.2338516   0.09259073\n",
      "  -0.17590415 -0.16401525  0.35294248 -0.11469077 -0.09241004  0.31818073\n",
      "   0.09319133  0.15336976  0.48800756  0.11664617]\n",
      " [-0.25026617 -0.34506524 -0.00638696  0.03429149  0.00531409  0.16995762\n",
      "  -0.09415686  0.4987678  -0.33076687 -0.14480283  0.37709159  0.22835203\n",
      "   0.23343498 -0.23239478  0.24518526 -0.19287073]\n",
      " [-0.25232878  0.04896386  0.23218686 -0.36998449  0.33409074  0.22950349\n",
      "   0.10688574  0.14016081 -0.03974051 -0.30911762 -0.21588889  0.07387955\n",
      "  -0.20960364 -0.21282821 -0.08385389  0.54983193]\n",
      " [-0.25718579  0.04954874  0.0677794  -0.29876807 -0.07297345 -0.26742974\n",
      "  -0.04767604  0.04718847 -0.32440686  0.50738956 -0.07384704  0.41850577\n",
      "  -0.3770039   0.25219395  0.0606774  -0.05916529]\n",
      " [-0.27012961 -0.06989448 -0.33687265  0.14476201  0.35262974 -0.03558689\n",
      "  -0.29762875 -0.2087025   0.17994245 -0.12058314 -0.11173965 -0.02543497\n",
      "  -0.4771762  -0.3068892   0.19274645 -0.33297177]\n",
      " [-0.2398744   0.33681459 -0.1290929  -0.36304005 -0.06875791  0.32247302\n",
      "  -0.12815771  0.06101286 -0.16323459 -0.03214142 -0.24114736 -0.44784975\n",
      "   0.19657017  0.26991459  0.30004815 -0.25252134]\n",
      " [-0.23624951  0.13087068 -0.48401684  0.14050801 -0.08456687  0.00062357\n",
      "   0.05975666 -0.05897425 -0.09355734 -0.41490693 -0.19177829  0.44902766\n",
      "   0.18836278  0.30274331 -0.3352383  -0.00438448]\n",
      " [-0.25553203 -0.15729271  0.19646905 -0.05062453  0.58094437  0.12898076\n",
      "   0.16775505 -0.03984342  0.33930866  0.21184413  0.15352998  0.04285688\n",
      "   0.24637906  0.34815767 -0.22669879 -0.25731806]\n",
      " [-0.25965327  0.399659    0.22965486 -0.06270473 -0.17637399  0.13403059\n",
      "   0.1175103  -0.37665013 -0.13036528  0.07359792  0.19476972  0.09705852\n",
      "   0.13077879 -0.50912779 -0.3058228  -0.26800095]\n",
      " [-0.22780955  0.10489963  0.28992879  0.40816046 -0.00699093 -0.2754241\n",
      "  -0.05466299  0.47539014 -0.04726021  0.04431572 -0.46064239 -0.22156451\n",
      "   0.01972664 -0.09597993 -0.28661908 -0.15595717]\n",
      " [-0.26095988 -0.09522792  0.04575537 -0.30505837 -0.32441947 -0.41483825\n",
      "   0.37524963  0.10801273  0.32444517 -0.36301579  0.22773246 -0.18257156\n",
      "  -0.19689573  0.07205539  0.0224313  -0.17651335]]\n",
      "std basis: \n",
      "[[0.18697999 0.00946685 0.9670297  ... 0.59085596 0.30937354 0.28234243]\n",
      " [0.93907673 0.83903802 0.17819681 ... 0.20240386 0.07793741 0.32545908]\n",
      " [0.38885846 0.7029656  0.56495339 ... 0.29405898 0.1997843  0.48416765]\n",
      " ...\n",
      " [0.29869945 0.48983416 0.44397705 ... 0.98208701 0.61166701 0.32790495]\n",
      " [0.69407421 0.59401725 0.36016333 ... 0.44017886 0.98862212 0.00302284]\n",
      " [0.88464183 0.43175692 0.65873971 ... 0.69402391 0.79729973 0.68414368]]\n",
      "haar basis: \n",
      "[[ 4.95565116  5.42560636  5.3907532  ...  5.02476133  5.9490905\n",
      "   6.19071492]\n",
      " [-1.07842622 -0.89139797  0.36817247 ... -0.50007184  0.91531673\n",
      "  -0.56754497]\n",
      " [ 0.28667945 -1.080662    0.505316   ...  0.59343215 -1.04012098\n",
      "  -0.17616119]\n",
      " ...\n",
      " [-0.82594223 -0.63146895  0.26807327 ...  0.46600685 -1.23931646\n",
      "  -0.46703678]\n",
      " [-1.75308432 -0.35200827 -0.72592207 ...  0.64601075 -0.69470382\n",
      "  -0.38841081]\n",
      " [-0.25324431 -0.13983261  0.08157976 ...  0.66523378 -0.10560318\n",
      "   1.25793823]]\n",
      "eigen basis: \n",
      "[[-1.72845352e+00 -1.87618466e+00 -1.93411622e+00 ... -1.78748006e+00\n",
      "  -2.12329714e+00 -2.20310019e+00]\n",
      " [ 4.02328507e-01  6.85834993e-01 -5.65011479e-01 ...  4.29328295e-01\n",
      "  -6.61391868e-01 -6.35932656e-02]\n",
      " [ 4.99762138e-01 -2.54939452e-01 -4.93158271e-01 ...  1.25907871e-02\n",
      "   7.37940177e-01  7.05328939e-02]\n",
      " ...\n",
      " [ 1.90799210e-01 -2.87898020e-02  2.23655927e-02 ... -5.23111591e-02\n",
      "  -2.68619552e-01  3.07848915e-01]\n",
      " [ 4.56746464e-01  4.10030327e-01 -5.70557382e-01 ... -2.21630843e-01\n",
      "  -3.52171110e-01  4.93599160e-01]\n",
      " [ 3.13435303e-01  9.99970506e-03 -8.54258921e-04 ... -5.55177598e-01\n",
      "  -5.09879062e-02  8.15696025e-02]]\n",
      "std mean: \n",
      "[0.52865614 0.43080597 0.45848074 0.51398294 0.52647514 0.49870713\n",
      " 0.49475961 0.5009777  0.51279897 0.53341847 0.47746794 0.48030773\n",
      " 0.51111384 0.51855891 0.45831974 0.52129997]\n",
      "std var: \n",
      "[0.07950309 0.08542397 0.07115153 0.07211246 0.09004236 0.09060213\n",
      " 0.07368645 0.09152547 0.07098556 0.08737226 0.09097271 0.07409634\n",
      " 0.08549858 0.0855929  0.07423172 0.07538538]\n",
      "haar mean: \n",
      "[ 5.63290521e+00 -2.12038038e-02  1.09557854e-01  1.59165451e-01\n",
      " -6.66753281e-02  4.79164403e-02 -2.86929609e-03  3.25632629e-02\n",
      " -4.27376985e-02  1.11569059e-01 -8.63033891e-02  1.05771167e-01\n",
      " -5.91809026e-02 -1.85035376e-02 -5.71591496e-02  1.36246141e-01]\n",
      "haar var: \n",
      "[0.62209428 0.52002673 0.54521918 0.81091325 0.77527291 0.84244042\n",
      " 0.4799715  0.58134399 0.73778867 0.7921123  0.72195874 0.52801052\n",
      " 0.60311538 0.51601506 0.71939443 0.58978587]\n",
      "eig mean: \n",
      "[-1.99472891e+00  6.00155909e-03 -3.77901192e-03  1.29197600e-03\n",
      "  1.75375396e-03 -9.67391298e-03  2.75592531e-03 -5.77229840e-04\n",
      " -1.61585466e-03 -1.49183919e-03 -1.86791364e-03  1.40347262e-03\n",
      "  8.26697576e-03  3.58406785e-03 -5.43445584e-03  2.07330135e-03]\n",
      "eig var: \n",
      "[0.08026681 0.13971518 0.12169805 0.11973262 0.10900635 0.1046426\n",
      " 0.03857512 0.04078853 0.04848766 0.05078532 0.05192818 0.06480181\n",
      " 0.07135589 0.0788081  0.08893021 0.08866047]\n"
     ]
    }
   ],
   "source": [
    "x = np.random.rand(16,100)\n",
    "print x.shape[0]\n",
    "m = autoCovariance(x)\n",
    "e = expectationVector(x)\n",
    "v = varianceVector(x, e)\n",
    "if isSymmetric(m):\n",
    "    print \"symmetric\"\n",
    "    \n",
    "else:\n",
    "    print \"not symmetric\"\n",
    "    \n",
    "eigval, eigvec = np.linalg.eig(m)\n",
    "print eigval\n",
    "print eigvec\n",
    "\n",
    "std_basis = np.zeros((x.shape[0], x.shape[1]))\n",
    "haar_basis = np.zeros((x.shape[0], x.shape[1]))\n",
    "eig_basis = np.zeros((x.shape[0], x.shape[1]))\n",
    "\n",
    "for n in range(x.shape[1]):\n",
    "    std_basis[:,n] = std_basis_variance(x[:, n])\n",
    "    haar_basis[:,n] = haar_basis_variance(x[:, n])\n",
    "    eig_basis[:,n] = eig_basis_variance(x[:, n], eigvec)\n",
    "                     \n",
    "print \"std basis: \\n\", std_basis\n",
    "print \"haar basis: \\n\", haar_basis\n",
    "print \"eigen basis: \\n\", eig_basis\n",
    "\n",
    "std_e = expectationVector(std_basis)\n",
    "std_v = varianceVector(std_basis, std_e)\n",
    "haar_e = expectationVector(haar_basis)\n",
    "haar_v = varianceVector(haar_basis, haar_e)\n",
    "eig_e = expectationVector(eig_basis)\n",
    "eig_v = varianceVector(eig_basis, eig_e)\n",
    "\n",
    "print \"std mean: \\n\", std_e\n",
    "print \"std var: \\n\", std_v\n",
    "print \"haar mean: \\n\", haar_e\n",
    "print \"haar var: \\n\", haar_v\n",
    "print \"eig mean: \\n\", eig_e\n",
    "print \"eig var: \\n\", eig_v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.\n",
    "\n",
    "#### Problem Statement\n",
    "\n",
    "Create a McCulloch-Pitts (MCP) neural network of n linearly arranged neurons as per the mathematical model below. The input should be a single boolean value ($x=1$) and will propagate along the network. Then perturb the network with random spikes as a function of time.\n",
    "\n",
    "$u_{i}(n + 1) = \\Phi [\\Sigma_{j} w_{i,j} u_{j} (n) − v_{TH}]$\n",
    "\n",
    "#### Analysis\n",
    "\n",
    "By propogating a boolean value along the linearly arranged network, the output matches exactly the input. Given that the activation function was a unit step function (e.g. $f(x) = [0, 1]$) the threshold value $v_{TH} = 0.5$. By perturbing the system with random spikes of noise, the network failes to generalize to anything outside the range of the activation function. Thus, the network reports a high number of false positives given any amount of noise outside a boolean range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class neuron():\n",
    "    def __init__(self, num_layers, num_neurons, threshold, initial_condition):\n",
    "        self.i = num_neurons\n",
    "        self.j = num_layers\n",
    "        self.v = threshold\n",
    "        self.u = initial_condition\n",
    "        self.w = np.ones((num_layers, num_neurons))\n",
    "        \n",
    "    def unit_step(self, x):\n",
    "        if x >= 0:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    def predict(self):\n",
    "        u_j = self.u\n",
    "        print u_j\n",
    "        for j in range(self.j-1):\n",
    "            for i in range(self.i):\n",
    "                output = self.unit_step(np.dot(self.w[j, i],u_j) - self.v)\n",
    "                u_j = output\n",
    "\n",
    "        print output\n",
    "        error = 1 - output\n",
    "        accuracy = float(1 - error)/1.0\n",
    "        print \"accuracy: \\n\", accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "accuracy: \n",
      "1.0\n",
      "-3.60409627958\n",
      "0\n",
      "accuracy: \n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "data = 1\n",
    "mcp = neuron(3, 1, 0.5, data)\n",
    "mcp.predict()\n",
    "\n",
    "noise_data = np.random.uniform(-10, 10)\n",
    "mcp_noise = neuron(3, 1, 0.5, noise_data)\n",
    "mcp_noise.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
